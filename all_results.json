{
  "runs": [
    {
      "run_id": 1,
      "hypothesis": "Files with content containing a significantly higher number of special characters compared to alphabetic characters might contain bad data.",
      "filter_code": "any(not c.isalnum() and not c.isspace() for c in fname)",
      "filter_result": {
        "filtered_count": 9,
        "sample_evaluations": [
          [
            "5.txt",
            true
          ],
          [
            "7.txt",
            true
          ],
          [
            "8.txt",
            true
          ],
          [
            "6.txt",
            true
          ],
          [
            "4.txt",
            true
          ]
        ],
        "first_matches": [
          "5.txt",
          "7.txt",
          "8.txt",
          "6.txt",
          "4.txt"
        ],
        "output_path": "/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run1.txt",
        "summary": "Saved 9 matching filenames to '/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run1.txt'."
      },
      "confidence_result": {
        "confidence": 0.6,
        "bad": 3,
        "total": 5,
        "summary": "Confidence: 0.60, Bad: 3, Total: 5",
        "metrics": {
          "precision": 0.6,
          "recall": 0.6,
          "f1_score": 0.6,
          "accuracy": 0.92,
          "confidence": 0.6,
          "verdict": {
            "text": "Good - This hypothesis is reliable at identifying bad data",
            "score": 0.6
          }
        }
      },
      "metrics": {
        "precision": 0.6,
        "recall": 0.6,
        "f1_score": 0.6,
        "accuracy": 0.92,
        "confidence": 0.6,
        "verdict": {
          "text": "Good - This hypothesis is reliable at identifying bad data",
          "score": 0.6
        }
      },
      "timestamp": "2025-05-02 14:26:11",
      "is_unique": true
    },
    {
      "run_id": 2,
      "hypothesis": "Files that contain content consisting of a single repeated character or a limited set of characters might contain bad data.",
      "filter_code": "not fname.replace('.', '').isalnum()",
      "filter_result": {
        "filtered_count": 0,
        "sample_evaluations": [
          [
            "5.txt",
            false
          ],
          [
            "7.txt",
            false
          ],
          [
            "8.txt",
            false
          ],
          [
            "6.txt",
            false
          ],
          [
            "4.txt",
            false
          ]
        ],
        "first_matches": [],
        "output_path": "/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run2.txt",
        "summary": "No files matched the filter."
      },
      "confidence_result": {
        "confidence": 0.0,
        "bad": 0,
        "total": 0,
        "summary": "No files to analyze",
        "metrics": {
          "precision": 0.0,
          "recall": 0.0,
          "f1_score": 0,
          "accuracy": 0.0,
          "confidence": 0.0,
          "verdict": {
            "text": "Very Poor - This hypothesis fails to meaningfully identify bad data",
            "score": 0.0
          }
        }
      },
      "metrics": {
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0,
        "accuracy": 0.0,
        "confidence": 0.0,
        "verdict": {
          "text": "Very Poor - This hypothesis fails to meaningfully identify bad data",
          "score": 0.0
        }
      },
      "timestamp": "2025-05-02 14:26:12",
      "is_unique": true
    },
    {
      "run_id": 3,
      "hypothesis": "Files that contain content with a significantly higher ratio of consonants to vowels might contain bad data.",
      "filter_code": "sum(1 for letter in fname.lower() if letter.isalpha() and letter not in 'aeiou') / max(1, sum(1 for letter in fname.lower() if letter.isalpha() and letter in 'aeiou')) > 2.0",
      "filter_result": {
        "filtered_count": 9,
        "sample_evaluations": [
          [
            "5.txt",
            true
          ],
          [
            "7.txt",
            true
          ],
          [
            "8.txt",
            true
          ],
          [
            "6.txt",
            true
          ],
          [
            "4.txt",
            true
          ]
        ],
        "first_matches": [
          "5.txt",
          "7.txt",
          "8.txt",
          "6.txt",
          "4.txt"
        ],
        "output_path": "/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run3.txt",
        "summary": "Saved 9 matching filenames to '/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run3.txt'."
      },
      "confidence_result": {
        "confidence": 0.6,
        "bad": 3,
        "total": 5,
        "summary": "Confidence: 0.60, Bad: 3, Total: 5",
        "metrics": {
          "precision": 0.6,
          "recall": 0.6,
          "f1_score": 0.6,
          "accuracy": 0.92,
          "confidence": 0.6,
          "verdict": {
            "text": "Good - This hypothesis is reliable at identifying bad data",
            "score": 0.6
          }
        }
      },
      "metrics": {
        "precision": 0.6,
        "recall": 0.6,
        "f1_score": 0.6,
        "accuracy": 0.92,
        "confidence": 0.6,
        "verdict": {
          "text": "Good - This hypothesis is reliable at identifying bad data",
          "score": 0.6
        }
      },
      "timestamp": "2025-05-02 14:26:15",
      "is_unique": true
    },
    {
      "run_id": 4,
      "hypothesis": "Files that have an uneven or irregular distribution of line breaks within the content might contain bad data.",
      "filter_code": "int(fname.split('.')[0]) % 2 == 0",
      "filter_result": {
        "filtered_count": 5,
        "sample_evaluations": [
          [
            "5.txt",
            false
          ],
          [
            "7.txt",
            false
          ],
          [
            "8.txt",
            true
          ],
          [
            "6.txt",
            true
          ],
          [
            "4.txt",
            true
          ]
        ],
        "first_matches": [
          "8.txt",
          "6.txt",
          "4.txt",
          "2.txt",
          "10.txt"
        ],
        "output_path": "/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run4.txt",
        "summary": "Saved 5 matching filenames to '/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run4.txt'."
      },
      "confidence_result": {
        "confidence": 0.8,
        "bad": 4,
        "total": 5,
        "summary": "Confidence: 0.80, Bad: 4, Total: 5",
        "metrics": {
          "precision": 0.8,
          "recall": 0.8,
          "f1_score": 0.8,
          "accuracy": 0.96,
          "confidence": 0.8,
          "verdict": {
            "text": "Excellent - This hypothesis very effectively identifies bad data",
            "score": 0.8
          }
        }
      },
      "metrics": {
        "precision": 0.8,
        "recall": 0.8,
        "f1_score": 0.8,
        "accuracy": 0.96,
        "confidence": 0.8,
        "verdict": {
          "text": "Excellent - This hypothesis very effectively identifies bad data",
          "score": 0.8
        }
      },
      "timestamp": "2025-05-02 14:26:17",
      "is_unique": true
    },
    {
      "run_id": 5,
      "hypothesis": "Files that contain a significantly higher frequency of random or nonsensical sequences of characters compared to coherent text might contain bad data.",
      "filter_code": "any(not c.isalnum() and not c.isspace() for c in fname)",
      "filter_result": {
        "filtered_count": 9,
        "sample_evaluations": [
          [
            "5.txt",
            true
          ],
          [
            "7.txt",
            true
          ],
          [
            "8.txt",
            true
          ],
          [
            "6.txt",
            true
          ],
          [
            "4.txt",
            true
          ]
        ],
        "first_matches": [
          "5.txt",
          "7.txt",
          "8.txt",
          "6.txt",
          "4.txt"
        ],
        "output_path": "/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run5.txt",
        "summary": "Saved 9 matching filenames to '/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run5.txt'."
      },
      "confidence_result": {
        "confidence": 1.0,
        "bad": 4,
        "total": 4,
        "summary": "Confidence: 1.00, Bad: 4, Total: 4",
        "metrics": {
          "precision": 1.0,
          "recall": 1.0,
          "f1_score": 1.0,
          "accuracy": 1.0,
          "confidence": 1.0,
          "verdict": {
            "text": "Excellent - This hypothesis very effectively identifies bad data",
            "score": 1.0
          }
        }
      },
      "metrics": {
        "precision": 1.0,
        "recall": 1.0,
        "f1_score": 1.0,
        "accuracy": 1.0,
        "confidence": 1.0,
        "verdict": {
          "text": "Excellent - This hypothesis very effectively identifies bad data",
          "score": 1.0
        }
      },
      "timestamp": "2025-05-02 14:26:19",
      "is_unique": true
    },
    {
      "run_id": 6,
      "hypothesis": "Files that have a content length that is not a multiple of a specific number of characters might contain bad data.",
      "filter_code": "len(fname) % 5 != 0",
      "filter_result": {
        "filtered_count": 1,
        "sample_evaluations": [
          [
            "5.txt",
            false
          ],
          [
            "7.txt",
            false
          ],
          [
            "8.txt",
            false
          ],
          [
            "6.txt",
            false
          ],
          [
            "4.txt",
            false
          ]
        ],
        "first_matches": [
          "10.txt"
        ],
        "output_path": "/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run6.txt",
        "summary": "Saved 1 matching filenames to '/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run6.txt'."
      },
      "confidence_result": {
        "confidence": 1.0,
        "bad": 1,
        "total": 1,
        "summary": "Confidence: 1.00, Bad: 1, Total: 1",
        "metrics": {
          "precision": 1.0,
          "recall": 1.0,
          "f1_score": 1.0,
          "accuracy": 1.0,
          "confidence": 1.0,
          "verdict": {
            "text": "Excellent - This hypothesis very effectively identifies bad data",
            "score": 1.0
          }
        }
      },
      "metrics": {
        "precision": 1.0,
        "recall": 1.0,
        "f1_score": 1.0,
        "accuracy": 1.0,
        "confidence": 1.0,
        "verdict": {
          "text": "Excellent - This hypothesis very effectively identifies bad data",
          "score": 1.0
        }
      },
      "timestamp": "2025-05-02 14:26:21",
      "is_unique": true
    },
    {
      "run_id": 7,
      "hypothesis": "Files that contain content with a high frequency of punctuation marks compared to the total number of characters might contain bad data.",
      "filter_code": "any(c.isdigit() for c in fname)",
      "filter_result": {
        "filtered_count": 9,
        "sample_evaluations": [
          [
            "5.txt",
            true
          ],
          [
            "7.txt",
            true
          ],
          [
            "8.txt",
            true
          ],
          [
            "6.txt",
            true
          ],
          [
            "4.txt",
            true
          ]
        ],
        "first_matches": [
          "5.txt",
          "7.txt",
          "8.txt",
          "6.txt",
          "4.txt"
        ],
        "output_path": "/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run7.txt",
        "summary": "Saved 9 matching filenames to '/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run7.txt'."
      },
      "confidence_result": {
        "confidence": 1.0,
        "bad": 4,
        "total": 4,
        "summary": "Confidence: 1.00, Bad: 4, Total: 4",
        "metrics": {
          "precision": 1.0,
          "recall": 1.0,
          "f1_score": 1.0,
          "accuracy": 1.0,
          "confidence": 1.0,
          "verdict": {
            "text": "Excellent - This hypothesis very effectively identifies bad data",
            "score": 1.0
          }
        }
      },
      "metrics": {
        "precision": 1.0,
        "recall": 1.0,
        "f1_score": 1.0,
        "accuracy": 1.0,
        "confidence": 1.0,
        "verdict": {
          "text": "Excellent - This hypothesis very effectively identifies bad data",
          "score": 1.0
        }
      },
      "timestamp": "2025-05-02 14:26:23",
      "is_unique": true
    },
    {
      "run_id": 8,
      "hypothesis": "Files that contain content with a high frequency of repeated characters in close proximity might contain bad data.",
      "filter_code": "not fname.replace('.', '').isalnum()",
      "filter_result": {
        "filtered_count": 0,
        "sample_evaluations": [
          [
            "5.txt",
            false
          ],
          [
            "7.txt",
            false
          ],
          [
            "8.txt",
            false
          ],
          [
            "6.txt",
            false
          ],
          [
            "4.txt",
            false
          ]
        ],
        "first_matches": [],
        "output_path": "/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run8.txt",
        "summary": "No files matched the filter."
      },
      "confidence_result": {
        "confidence": 0.0,
        "bad": 0,
        "total": 0,
        "summary": "No files to analyze",
        "metrics": {
          "precision": 0.0,
          "recall": 0.0,
          "f1_score": 0,
          "accuracy": 0.0,
          "confidence": 0.0,
          "verdict": {
            "text": "Very Poor - This hypothesis fails to meaningfully identify bad data",
            "score": 0.0
          }
        }
      },
      "metrics": {
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0,
        "accuracy": 0.0,
        "confidence": 0.0,
        "verdict": {
          "text": "Very Poor - This hypothesis fails to meaningfully identify bad data",
          "score": 0.0
        }
      },
      "timestamp": "2025-05-02 14:26:24",
      "is_unique": true
    },
    {
      "run_id": 9,
      "hypothesis": "Files that contain a high frequency of non-alphabetic characters, such as symbols or special characters, might contain bad data.",
      "filter_code": "any(not c.isalnum() and not c.isspace() for c in fname)",
      "filter_result": {
        "filtered_count": 9,
        "sample_evaluations": [
          [
            "5.txt",
            true
          ],
          [
            "7.txt",
            true
          ],
          [
            "8.txt",
            true
          ],
          [
            "6.txt",
            true
          ],
          [
            "4.txt",
            true
          ]
        ],
        "first_matches": [
          "5.txt",
          "7.txt",
          "8.txt",
          "6.txt",
          "4.txt"
        ],
        "output_path": "/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run9.txt",
        "summary": "Saved 9 matching filenames to '/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run9.txt'."
      },
      "confidence_result": {
        "confidence": 0.6,
        "bad": 3,
        "total": 5,
        "summary": "Confidence: 0.60, Bad: 3, Total: 5",
        "metrics": {
          "precision": 0.6,
          "recall": 0.6,
          "f1_score": 0.6,
          "accuracy": 0.92,
          "confidence": 0.6,
          "verdict": {
            "text": "Good - This hypothesis is reliable at identifying bad data",
            "score": 0.6
          }
        }
      },
      "metrics": {
        "precision": 0.6,
        "recall": 0.6,
        "f1_score": 0.6,
        "accuracy": 0.92,
        "confidence": 0.6,
        "verdict": {
          "text": "Good - This hypothesis is reliable at identifying bad data",
          "score": 0.6
        }
      },
      "timestamp": "2025-05-02 14:26:26",
      "is_unique": true
    },
    {
      "run_id": 10,
      "hypothesis": "Files that contain content with a high frequency of irregular line breaks or inconsistent line lengths might contain bad data.",
      "filter_code": "len(fname) > 10",
      "filter_result": {
        "filtered_count": 0,
        "sample_evaluations": [
          [
            "5.txt",
            false
          ],
          [
            "7.txt",
            false
          ],
          [
            "8.txt",
            false
          ],
          [
            "6.txt",
            false
          ],
          [
            "4.txt",
            false
          ]
        ],
        "first_matches": [],
        "output_path": "/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run10.txt",
        "summary": "No files matched the filter."
      },
      "confidence_result": {
        "confidence": 0.0,
        "bad": 0,
        "total": 0,
        "summary": "No files to analyze",
        "metrics": {
          "precision": 0.0,
          "recall": 0.0,
          "f1_score": 0,
          "accuracy": 0.0,
          "confidence": 0.0,
          "verdict": {
            "text": "Very Poor - This hypothesis fails to meaningfully identify bad data",
            "score": 0.0
          }
        }
      },
      "metrics": {
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0,
        "accuracy": 0.0,
        "confidence": 0.0,
        "verdict": {
          "text": "Very Poor - This hypothesis fails to meaningfully identify bad data",
          "score": 0.0
        }
      },
      "timestamp": "2025-05-02 14:26:28",
      "is_unique": true
    }
  ],
  "best_run": {
    "run_id": 5,
    "hypothesis": "Files that contain a significantly higher frequency of random or nonsensical sequences of characters compared to coherent text might contain bad data.",
    "filter_code": "any(not c.isalnum() and not c.isspace() for c in fname)",
    "filter_result": {
      "filtered_count": 9,
      "sample_evaluations": [
        [
          "5.txt",
          true
        ],
        [
          "7.txt",
          true
        ],
        [
          "8.txt",
          true
        ],
        [
          "6.txt",
          true
        ],
        [
          "4.txt",
          true
        ]
      ],
      "first_matches": [
        "5.txt",
        "7.txt",
        "8.txt",
        "6.txt",
        "4.txt"
      ],
      "output_path": "/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run5.txt",
      "summary": "Saved 9 matching filenames to '/home/alex/code/local_projects/Antitodte_Intelegence2/junk_data/junk_data_run5.txt'."
    },
    "confidence_result": {
      "confidence": 1.0,
      "bad": 4,
      "total": 4,
      "summary": "Confidence: 1.00, Bad: 4, Total: 4",
      "metrics": {
        "precision": 1.0,
        "recall": 1.0,
        "f1_score": 1.0,
        "accuracy": 1.0,
        "confidence": 1.0,
        "verdict": {
          "text": "Excellent - This hypothesis very effectively identifies bad data",
          "score": 1.0
        }
      }
    },
    "metrics": {
      "precision": 1.0,
      "recall": 1.0,
      "f1_score": 1.0,
      "accuracy": 1.0,
      "confidence": 1.0,
      "verdict": {
        "text": "Excellent - This hypothesis very effectively identifies bad data",
        "score": 1.0
      }
    },
    "timestamp": "2025-05-02 14:26:19",
    "is_unique": true
  },
  "overall_verdict": {
    "overall_score": 1.0,
    "best_hypotheses": [
      {
        "run_id": 5,
        "hypothesis": "Files that contain a significantly higher frequency of random or nonsensical sequences of characters compared to coherent text might contain bad data.",
        "f1_score": 1.0,
        "precision": 1.0,
        "recall": 1.0,
        "verdict_score": 1.0,
        "verdict_text": "Excellent - This hypothesis very effectively identifies bad data"
      },
      {
        "run_id": 6,
        "hypothesis": "Files that have a content length that is not a multiple of a specific number of characters might contain bad data.",
        "f1_score": 1.0,
        "precision": 1.0,
        "recall": 1.0,
        "verdict_score": 1.0,
        "verdict_text": "Excellent - This hypothesis very effectively identifies bad data"
      },
      {
        "run_id": 7,
        "hypothesis": "Files that contain content with a high frequency of punctuation marks compared to the total number of characters might contain bad data.",
        "f1_score": 1.0,
        "precision": 1.0,
        "recall": 1.0,
        "verdict_score": 1.0,
        "verdict_text": "Excellent - This hypothesis very effectively identifies bad data"
      }
    ],
    "recommendation": "Multiple strong hypotheses found. Recommend using the top hypothesis for filtering bad data."
  }
}